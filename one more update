#!/bin/bash
# Fast & Safe CAAPI Log Analyzer with Top-N Leaderboard

LOG_FILE=""
SHOW_TOP=10
COLOR_OUTPUT=true
SHOW_SUMMARY=true
BUCKET_MIN=60

declare -a URL_PATTERNS
declare -a TIME_RANGES

# Colors
if [ "$COLOR_OUTPUT" = true ]; then
    RED='\033[0;31m'
    GREEN='\033[0;32m'
    CYAN='\033[0;36m'
    NC='\033[0m'
else
    RED=''; GREEN=''; CYAN=''; NC=''
fi

usage() {
    echo "Usage: $0 -f <logfile> [-u <url_pattern>] [-t <start-end>] [-b <bucket_min>] [-n <top>] [--no-color]"
    exit 1
}

# Parse arguments
while [[ $# -gt 0 ]]; do
    case $1 in
        -f) LOG_FILE="$2"; shift 2 ;;
        -u) URL_PATTERNS+=("$2"); shift 2 ;;
        -t) TIME_RANGES+=("$2"); shift 2 ;;
        -b) BUCKET_MIN="$2"; shift 2 ;;
        -n) SHOW_TOP="$2"; shift 2 ;;
        --no-color) COLOR_OUTPUT=false; shift ;;
        -h) usage ;;
        *) echo "Unknown option: $1"; usage ;;
    esac
done

[[ -z "$LOG_FILE" || ! -f "$LOG_FILE" ]] && echo "Log file missing" && exit 1
[[ ${#URL_PATTERNS[@]} -eq 0 ]] && URL_PATTERNS=(".*")
[[ ${#TIME_RANGES[@]} -eq 0 ]] && TIME_RANGES=("0-23")

# Join arrays for awk
URL_REGEX=$(IFS="|"; echo "${URL_PATTERNS[*]}")
TIME_RANGES_STR=$(IFS=","; echo "${TIME_RANGES[*]}")

awk -v bucket="$BUCKET_MIN" -v top="$SHOW_TOP" -v urls="$URL_REGEX" -v times="$TIME_RANGES_STR" \
    -v red="$RED" -v green="$GREEN" -v cyan="$CYAN" -v nc="$NC" '
BEGIN{
    split(times, tr, ",");
    OFS="|";
}

# Check if hour is in any range
function in_time_range(hr){
    for(i in tr){
        split(tr[i], t, "-");
        if(hr >= t[1] && hr <= t[2]) return 1;
    }
    return 0;
}

# Check if URL matches any pattern
function url_match(u){
    return (u ~ urls);
}

{
    ts=$1; url=""; status=""; elapsed="";

    for(i=1;i<=NF;i++){
        if($i~/ReqURL:/){url=$i; sub(/ReqURL::?/,"",url);}
        if($i~/SBRespCode:/){status=$i; sub(/SBRespCode::?/,"",status);}
        if($i~/ElapsedTime:/){elapsed=$i; sub(/ElapsedTime::?/,"",elapsed);}
    }

    if(status!=200 && status!=500) next;

    match(ts,/T([0-9]{2}):([0-9]{2})/, t);
    hr=t[1]+0; mn=t[2]+0;
    if(!in_time_range(hr)) next;
    if(!url_match(url)) next;

    bucket_mn=int(mn/bucket)*bucket;
    btime=sprintf("%02d:%02d", hr, bucket_mn);

    # Bucketed counts
    key=btime "|" url "|" status;
    count[key]++; sum[key]+=elapsed;

    # Aggregate summary per URL & code
    total[url "|" status]++; total_sum[url "|" status]+=elapsed;

    # Leaderboard counts per URL
    leaderboard[url "|" status]++; leaderboard_sum[url "|" status]+=elapsed;
}

END{
    print cyan "=== CAAPI Log Analysis (Bucketed) ===" nc;
    printf "%-8s %-50s %-6s %-8s %-10s\n","Time","URL","Code","Count","Avg(ms)";

    # Print bucketed stats
    for(k in count){
        split(k,a,"|"); bucket=a[1]; url=a[2]; code=a[3];
        avg=sum[k]/count[k];
        color=(code==200)?green:red;
        url_display=(length(url)>50)?substr(url,1,47)"...":url;
        printf "%-8s %-50s %s%-6s%s %-8d %-10.2f\n", bucket,url_display,color,code,nc,count[k],avg;
    }

    # Summary per URL
    if("'$SHOW_SUMMARY'"=="true"){
        print "\n" cyan "=== Summary per URL ===" nc;
        printf "%-50s %-6s %-8s %-10s\n","URL","Code","Total","Avg(ms)";
        for(k in total){
            split(k,a,"|"); url=a[1]; code=a[2];
            avg=total_sum[k]/total[k];
            color=(code==200)?green:red;
            url_display=(length(url)>50)?substr(url,1,47)"...":url;
            printf "%-50s %s%-6s%s %-8d %-10.2f\n", url_display,color,code,nc,total[k],avg;
        }
    }

    # Top-N Leaderboard per URL
    print "\n" cyan "=== Top-" top " Leaderboard per URL ===" nc;
    printf "%-50s %-6s %-8s %-10s %-10s\n","URL","Code","Count","Avg(ms)","Percentage";
    for(k in leaderboard){
        split(k,a,"|"); url=a[1]; code=a[2];
        avg=leaderboard_sum[k]/leaderboard[k];
        total_requests=0;
        for(j in leaderboard){
            split(j,b,"|");
            if(b[1]==url) total_requests+=leaderboard[j];
        }
        pct=(leaderboard[k]/total_requests)*100;
        color=(code==200)?green:red;
        url_display=(length(url)>50)?substr(url,1,47)"...":url;
        top_data[url_display "|" code]=leaderboard[k] "|" avg "|" pct;
    }

    # Sort leaderboard by count descending
    n=0;
    for(k in top_data){
        n++; split(top_data[k],v,"|");
        url_code=k; cnt=v[1]+0; avg=v[2]; pct=v[3];
        leaderboard_arr[n,"url_code"]=url_code; leaderboard_arr[n,"cnt"]=cnt; leaderboard_arr[n,"avg"]=avg; leaderboard_arr[n,"pct"]=pct;
    }

    PROCINFO["sorted_in"]="@val_num_desc";
    i=0;
    for(n=1;n<=length(leaderboard_arr);n++){
        url_code=leaderboard_arr[n,"url_code"];
        cnt=leaderboard_arr[n,"cnt"];
        avg=leaderboard_arr[n,"avg"];
        pct=leaderboard_arr[n,"pct"];
        split(url_code,a,"|"); url=a[1]; code=a[2];
        color=(code==200)?green:red;
        printf "%-50s %s%-6s%s %-8d %-10.2f %-9.2f%%\n", url, color, code, nc, cnt, avg, pct;
        i++;
        if(i>=top) break;
    }
}
' "$LOG_FILE"
# Analyze all URLs, default 1-hour bucket, show Top-10
./fast_caapi_analyzer.sh -f caapi.log

# Multiple URLs, multiple time ranges, 15-min bucket, show Top-5
./fast_caapi_analyzer.sh -f caapi.log -u "uploaddocument" -u "downloaddocument" -t 10-11 -t 12-13 -b 15 -n 5


#!/bin/bash
# CAAPI Log Analyzer: Real-time Mode with Top-N

LOG_FILE=""
SHOW_TOP=10
COLOR_OUTPUT=true
SHOW_SUMMARY=true
BUCKET_MIN=60
REALTIME=false

declare -a URL_PATTERNS
declare -a TIME_RANGES

# Colors
if [ "$COLOR_OUTPUT" = true ]; then
    RED='\033[0;31m'
    GREEN='\033[0;32m'
    CYAN='\033[0;36m'
    NC='\033[0m'
else
    RED=''; GREEN=''; CYAN=''; NC=''
fi

usage() {
    echo "Usage: $0 -f <logfile> [-u <url_pattern>] [-t <start-end>] [-b <bucket_min>] [-n <top>] [--realtime] [--no-color]"
    exit 1
}

# Parse args
while [[ $# -gt 0 ]]; do
    case $1 in
        -f) LOG_FILE="$2"; shift 2 ;;
        -u) URL_PATTERNS+=("$2"); shift 2 ;;
        -t) TIME_RANGES+=("$2"); shift 2 ;;
        -b) BUCKET_MIN="$2"; shift 2 ;;
        -n) SHOW_TOP="$2"; shift 2 ;;
        --realtime) REALTIME=true; shift ;;
        --no-color) COLOR_OUTPUT=false; shift ;;
        -h) usage ;;
        *) echo "Unknown option: $1"; usage ;;
    esac
done

[[ -z "$LOG_FILE" || ! -f "$LOG_FILE" ]] && echo "Log file missing" && exit 1
[[ ${#URL_PATTERNS[@]} -eq 0 ]] && URL_PATTERNS=(".*")
[[ ${#TIME_RANGES[@]} -eq 0 ]] && TIME_RANGES=("0-23")

URL_REGEX=$(IFS="|"; echo "${URL_PATTERNS[*]}")
TIME_RANGES_STR=$(IFS=","; echo "${TIME_RANGES[*]}")

# AWK script to process logs
AWK_SCRIPT=$(cat <<'EOF'
BEGIN{
    split(times, tr, ",");
    OFS="|";
}

function in_time_range(hr){
    for(i in tr){
        split(tr[i], t, "-");
        if(hr >= t[1] && hr <= t[2]) return 1;
    }
    return 0;
}

function url_match(u){
    return (u ~ urls);
}

{
    ts=$1; url=""; status=""; elapsed="";

    for(i=1;i<=NF;i++){
        if($i~/ReqURL:/){url=$i; sub(/ReqURL::?/,"",url);}
        if($i~/SBRespCode:/){status=$i; sub(/SBRespCode::?/,"",status);}
        if($i~/ElapsedTime:/){elapsed=$i; sub(/ElapsedTime::?/,"",elapsed);}
    }

    if(status!=200 && status!=500) next;

    match(ts,/T([0-9]{2}):([0-9]{2})/, t);
    hr=t[1]+0; mn=t[2]+0;
    if(!in_time_range(hr)) next;
    if(!url_match(url)) next;

    bucket_mn=int(mn/bucket)*bucket;
    btime=sprintf("%02d:%02d", hr, bucket_mn);

    key=btime "|" url "|" status;
    count[key]++; sum[key]+=elapsed;

    total[url "|" status]++; total_sum[url "|" status]+=elapsed;

    leaderboard[url "|" status]++; leaderboard_sum[url "|" status]+=elapsed;
}

END{
    function print_leaderboard(){
        print cyan "=== Top-" top " Leaderboard ===" nc;
        printf "%-50s %-6s %-8s %-10s %-10s\n","URL","Code","Count","Avg(ms)","Pct";

        delete top_data;
        for(k in leaderboard){
            split(k,a,"|"); url=a[1]; code=a[2];
            avg=leaderboard_sum[k]/leaderboard[k];
            total_requests=0;
            for(j in leaderboard){
                split(j,b,"|"); if(b[1]==url) total_requests+=leaderboard[j];
            }
            pct=(leaderboard[k]/total_requests)*100;
            color=(code==200)?green:red;
            url_display=(length(url)>50)?substr(url,1,47)"...":url;
            top_data[url_display "|" code]=leaderboard[k] "|" avg "|" pct;
        }

        n=0;
        for(k in top_data){
            n++; split(top_data[k],v,"|");
            url_code=k; cnt=v[1]; avg=v[2]; pct=v[3];
            leaderboard_arr[n,"url_code"]=url_code; leaderboard_arr[n,"cnt"]=cnt; leaderboard_arr[n,"avg"]=avg; leaderboard_arr[n,"pct"]=pct;
        }

        PROCINFO["sorted_in"]="@val_num_desc";
        i=0;
        for(n=1;n<=length(leaderboard_arr);n++){
            url_code=leaderboard_arr[n,"url_code"];
            cnt=leaderboard_arr[n,"cnt"];
            avg=leaderboard_arr[n,"avg"];
            pct=leaderboard_arr[n,"pct"];
            split(url_code,a,"|"); url=a[1]; code=a[2];
            color=(code==200)?green:red;
            printf "%-50s %s%-6s%s %-8d %-10.2f %-9.2f%%\n", url, color, code, nc, cnt, avg, pct;
            i++;
            if(i>=top) break;
        }
    }

    print_leaderboard();
}
EOF
)

if [ "$REALTIME" = true ]; then
    echo -e "${CYAN}Starting real-time monitoring of $LOG_FILE ...${NC}"
    tail -F "$LOG_FILE" | awk -v bucket="$BUCKET_MIN" -v top="$SHOW_TOP" \
        -v urls="$URL_REGEX" -v times="$TIME_RANGES_STR" \
        -v red="$RED" -v green="$GREEN" -v cyan="$CYAN" -v nc="$NC" "$AWK_SCRIPT"
else
    awk -v bucket="$BUCKET_MIN" -v top="$SHOW_TOP" \
        -v urls="$URL_REGEX" -v times="$TIME_RANGES_STR" \
        -v red="$RED" -v green="$GREEN" -v cyan="$CYAN" -v nc="$NC" "$AWK_SCRIPT" "$LOG_FILE"
fi
# Static analysis (existing log)
./caapi_analyzer.sh -f caapi.log -u "uploaddocument" -t 10-11 -b 15 -n 5

# Real-time monitoring
./caapi_analyzer.sh -f caapi.log --realtime -u "uploaddocument" -t 10-11 -b 15 -n 5
