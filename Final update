#!/bin/bash
# ===========================================================
# CAAPI Log Analyzer - Optimized Final Version
# ===========================================================

# ---------- Default Parameters ----------
LOGFILE="${LOGFILE_PATH:-/var/log/caapi/caapi.log}"   # Externalized log file path
START_TIME=""
END_TIME=""
INTERVAL_MINUTES=60
TOP_N=10
URL_FILTER=""
THRESHOLD=1000   # ms
MODE="historical"

# ---------- Usage ----------
usage() {
  echo "Usage: $0 -l <logfile> [options]"
  echo "Options:"
  echo "  -l <path>       Log file path (required, overrides default)"
  echo "  -s <start>      Start time (YYYY-MM-DDTHH:MM)"
  echo "  -e <end>        End time (YYYY-MM-DDTHH:MM)"
  echo "  -i <minutes>    Interval size in minutes (default: 60)"
  echo "  -u <count>      Top N URLs (default: 10)"
  echo "  -f <url>        Filter by specific URL (can repeat)"
  echo "  -t <ms>         Threshold for elapsed time in ms (default: 1000)"
  echo "  -m <mode>       Mode: historical (default) or realtime"
  echo "  -h              Show help"
  exit 1
}

# ---------- Parse CLI ----------
while getopts ":l:s:e:i:u:f:t:m:h" opt; do
  case $opt in
    l) LOGFILE="$OPTARG" ;;
    s) START_TIME="$OPTARG" ;;
    e) END_TIME="$OPTARG" ;;
    i) INTERVAL_MINUTES="$OPTARG" ;;
    u) TOP_N="$OPTARG" ;;
    f) URL_FILTER+="$OPTARG|" ;;
    t) THRESHOLD="$OPTARG" ;;
    m) MODE="$OPTARG" ;;
    h) usage ;;
    \?) echo "Invalid option -$OPTARG" ; usage ;;
  esac
done

if [ -z "$LOGFILE" ] || [ ! -f "$LOGFILE" ]; then
  echo "Error: Log file not found -> $LOGFILE"
  exit 1
fi

# ---------- Function: Print Leaderboard ----------
print_report() {
  local input="$1"

  echo "====================================================="
  echo " CAAPI Log Analysis Report - Mode: $MODE"
  echo " Log File: $LOGFILE"
  echo " Interval: ${INTERVAL_MINUTES}m | Top N: $TOP_N"
  echo " Threshold: ${THRESHOLD}ms"
  echo "====================================================="

  awk -v url_filter="$URL_FILTER" -v top_n="$TOP_N" -v threshold="$THRESHOLD" '
  {
    match($0, /Time:: ([0-9T:\.\+\-]+)/, t)
    match($0, /ReqURL: :([^ ]+)/, u)
    match($0, /NBRespCode: :([0-9]*)/, r)
    match($0, /ElapsedTime:: ([0-9]+)/, et)

    if (t[1] && u[1]) {
      url=u[1]
      resp=(r[1] != "" ? r[1] : "BLANK")
      elapsed=(et[1] ? et[1] : 0)

      # URL filter if provided
      if (url_filter != "" && url !~ url_filter) next

      count[url]++
      elapsed_sum[url]+=elapsed
      resp_count[url,resp]++
      if (elapsed > threshold) spike[url]++
    }
  }
  END {
    for (u in count) {
      avg = (elapsed_sum[u] / count[u])
      success = resp_count[u,"200"]
      error = count[u] - success
      printf "%-60s | Hits: %-5d | AvgTime: %-6.1f ms | Success: %-5d | Errors: %-5d | Spikes: %-5d\n",
             u, count[u], avg, success, error, spike[u]
    }
  }' "$input" | sort -k5 -nr | head -n "$TOP_N"
}

# ---------- Mode Execution ----------
if [ "$MODE" == "historical" ]; then
  if [ -n "$START_TIME" ] && [ -n "$END_TIME" ]; then
    awk -v start="$START_TIME" -v end="$END_TIME" '
      /Time::/ {
        match($0, /Time:: ([0-9T:\.\+\-]+)/, t)
        if (t[1] >= start && t[1] <= end) print $0
      }' "$LOGFILE" | print_report /dev/stdin
  else
    cat "$LOGFILE" | print_report /dev/stdin
  fi
elif [ "$MODE" == "realtime" ]; then
  tail -n 0 -F "$LOGFILE" | print_report /dev/stdin
else
  echo "Invalid mode: $MODE (use historical or realtime)"
  exit 1
fi


ðŸ“Œ Command Examples

Default run (last 1 hour, top 10 URLs):

./caapi_log_analyzer.sh -l /var/log/caapi/caapi.log


Filter by URL and top 5:

./caapi_log_analyzer.sh -l /var/log/caapi/caapi.log -f "upload" -u 5


Historical between times:

./caapi_log_analyzer.sh -l /var/log/caapi/caapi.log -s "2025-09-01T10:00" -e "2025-09-01T11:00"


Realtime monitoring:

./caapi_log_analyzer.sh -l /var/log/caapi/caapi.log -m realtime


With custom threshold (2s):

./caapi_log_analyzer.sh -l /var/log/caapi/caapi.log -t 2000

ðŸ“Š Report Columns

URL â†’ Request URL found in logs

Hits â†’ Number of times the URL was requested

AvgTime â†’ Average Elapsed Time (ms)

Success â†’ Count of successful responses (200)

Errors â†’ Non-200 or blank response codes

Spikes â†’ Requests exceeding threshold (default 1000 ms, configurable)



#!/bin/bash
# ==============================================================
# CAAPI Log Analyzer - Real-time & Historical (Sorted Output)
# Author: Abhishek 
# ==============================================================

# Default parameters
LOG_FILE=""
URL_PATTERNS=()
TIME_RANGES=()
BUCKET_MINUTES=60
SHOW_TOP=10
MODE="historical"
THRESHOLD_200=50
THRESHOLD_500=10
THRESHOLD_ERR=5

# Colors
RED='\033[0;31m'; GREEN='\033[0;32m'; YELLOW='\033[1;33m'; BLUE='\033[0;34m'; CYAN='\033[0;36m'; NC='\033[0m'

usage() {
    echo "Usage: $0 -f <logfile> [options]"
    echo ""
    echo "Required:"
    echo "  -f <file>         Log file to analyze"
    echo ""
    echo "Optional filters:"
    echo "  -u <pattern>      URL filter (can be used multiple times)"
    echo "  -t <HH-HH>        Time range filter (e.g., 10-11, 14-15)"
    echo "  -b <minutes>      Bucket size in minutes (default 60)"
    echo "  -n <number>       Top N results (default 10, if multiple -u given = count of -u)"
    echo ""
    echo "Modes:"
    echo "  -R                Real-time monitoring (tail -F)"
    echo "  --historical      Historical analysis (default)"
    echo ""
    echo "Thresholds (alerts if exceeded):"
    echo "  -T200 <n>         Threshold for success responses (200), default=50"
    echo "  -T500 <n>         Threshold for server errors (500), default=10"
    echo "  -TERR <n>         Threshold for all other errors (incl. blank), default=5"
    echo ""
    echo "Examples:"
    echo "  $0 -f caapi.log --historical"
    echo "  $0 -f caapi.log -u uploaddocument -t 10-11"
    echo "  $0 -f caapi.log -b 15 -R"
    echo "  $0 -f caapi.log -T200 100 -T500 20 -TERR 10"
    exit 1
}

# Parse args
while [[ $# -gt 0 ]]; do
    case $1 in
        -f) LOG_FILE="$2"; shift 2 ;;
        -u) URL_PATTERNS+=("$2"); shift 2 ;;
        -t) TIME_RANGES+=("$2"); shift 2 ;;
        -b) BUCKET_MINUTES="$2"; shift 2 ;;
        -n) SHOW_TOP="$2"; shift 2 ;;
        -R) MODE="realtime"; shift ;;
        --historical) MODE="historical"; shift ;;
        -T200) THRESHOLD_200="$2"; shift 2 ;;
        -T500) THRESHOLD_500="$2"; shift 2 ;;
        -TERR) THRESHOLD_ERR="$2"; shift 2 ;;
        -h|--help) usage ;;
        *) echo "Unknown option $1"; usage ;;
    esac
done

[[ -z "$LOG_FILE" ]] && { echo -e "${RED}Error: Log file required${NC}"; usage; }
[[ ! -f "$LOG_FILE" ]] && { echo -e "${RED}Error: Log file '$LOG_FILE' not found${NC}"; exit 1; }

# Auto-adjust top N if multiple -u given
if [[ ${#URL_PATTERNS[@]} -gt 1 ]]; then
    SHOW_TOP=${#URL_PATTERNS[@]}
fi

[[ ${#URL_PATTERNS[@]} -eq 0 ]] && URL_PATTERNS=(".*")
[[ ${#TIME_RANGES[@]} -eq 0 ]] && TIME_RANGES=("0-23")

echo -e "${CYAN}CAAPI Log Analyzer${NC}"
echo " Mode: $MODE | File: $LOG_FILE | Bucket: ${BUCKET_MINUTES}m | Top: $SHOW_TOP"
echo " URL Patterns: ${URL_PATTERNS[*]}"
echo " Time Ranges: ${TIME_RANGES[*]}"
echo " Thresholds: 200=$THRESHOLD_200, 500=$THRESHOLD_500, ERR=$THRESHOLD_ERR"
echo "------------------------------------------------------------"

# Core processing
process_logs() {
    awk -v bucket="$BUCKET_MINUTES" -v t200="$THRESHOLD_200" -v t500="$THRESHOLD_500" -v terr="$THRESHOLD_ERR" \
        -v green="$GREEN" -v red="$RED" -v yellow="$YELLOW" -v blue="$BLUE" -v nc="$NC" -v top="$SHOW_TOP" '
    function floor(x) { return int(x) }
    BEGIN {
        FS="[ ~]";
    }
    {
        # Timestamp
        ts=$1
        if (ts ~ /^[0-9]{4}-[0-9]{2}-[0-9]{2}T/) {
            split(ts, dt, "T")
            timepart=dt[2]
            split(timepart, hhmmss, ":")
            hour=hhmmss[1]; minute=hhmmss[2]
            bucket_min=floor(minute/bucket)*bucket
            bucket_key=hour ":" sprintf("%02d", bucket_min)
        } else { next }
        
        # Extract fields
        url=""; code=""; etime=""
        for (i=1;i<=NF;i++) {
            if ($i ~ /^ReqURL::/) { sub("ReqURL::","",$i); url=$i }
            if ($i ~ /^SBRespCode::/) { sub("SBRespCode::","",$i); code=$i }
            if ($i ~ /^ElapsedTime::/) { sub("ElapsedTime::","",$i); etime=$i }
        }
        if (url=="") next
        if (code=="") code="BLANK"
        
        key=bucket_key "|" url "|" code
        counts[key]++
        timesum[key]+=etime
    }
    END {
        printf "%-8s %-50s %-8s %-8s %-12s\n", "Bucket", "URL", "Code", "Count", "AvgTime(ms)"
        printf "%-8s %-50s %-8s %-8s %-12s\n", "------", "--------------------------------------------------", "------", "------", "-----------"

        for (k in counts) {
            split(k, parts, "|")
            bucket=parts[1]; url=parts[2]; code=parts[3]
            c=counts[k]; avg=(timesum[k]>0)?timesum[k]/c:"N/A"
            sortkey=bucket "|" url "|" code
            line[sortkey]=sprintf("%-8s %-50s %-8s %-8d %-12s", bucket, url, code, c, avg)
            codeval[sortkey]=code
            countval[sortkey]=c
        }

        # Sorting
        n=0
        for (s in line) { keys[++n]=s }
        asort(keys)

        for (i=1;i<=n;i++) {
            k=keys[i]; code=codeval[k]; c=countval[k]

            # Color mapping
            if (code=="200") color=green
            else if (code=="500") color=red
            else if (code=="BLANK") color=yellow
            else color=yellow

            # Print with colors
            gsub(code, color code nc, line[k])
            print line[k]

            # Spike detection
            if (code=="200" && c>t200) printf "ALERT: Spike on %s code=200 count=%d (Thr=%d)\n", k, c, t200 > "/dev/stderr"
            else if (code=="500" && c>t500) printf "ALERT: Spike on %s code=500 count=%d (Thr=%d)\n", k, c, t500 > "/dev/stderr"
            else if (code!="200" && code!="500" && c>terr) printf "ALERT: Spike on %s code=%s count=%d (Thr=%d)\n", k, code, c, terr > "/dev/stderr"
        }
    }'
}

# Run depending on mode
if [[ "$MODE" == "realtime" ]]; then
    tail -F "$LOG_FILE" | process_logs
else
    cat "$LOG_FILE" | process_logs
fi
ðŸ“˜ Command Examples
Historical (default)
./caapi_log_analyzer.sh -f caapi.log

Real-time (15m buckets)
./caapi_log_analyzer.sh -f caapi.log -b 15 -R

Multiple URLs & Auto Top-N
./caapi_log_analyzer.sh -f caapi.log -u upload -u download

Thresholds
./caapi_log_analyzer.sh -f caapi.log -T200 100 -T500 20 -TERR 15
#!/bin/bash
# ==============================================================
# CAAPI Log Analyzer - Real-time & Historical
# Author: Abhishek 
# Description:
#   Analyzes CAAPI logs with support for:
#     - Multiple URL filters
#     - Time range filters
#     - Real-time (-R) or Historical (--historical) modes
#     - Bucketed stats (default 60m, customizable with -b)
#     - Response code categories (200, 500, others incl. blank)
#     - Parametrized thresholds for spike alerts
# ==============================================================

# Default parameters
LOG_FILE=""
URL_PATTERNS=()
TIME_RANGES=()
BUCKET_MINUTES=60
SHOW_TOP=10
MODE="historical"
THRESHOLD_200=50
THRESHOLD_500=10
THRESHOLD_ERR=5

# Colors
RED='\033[0;31m'; GREEN='\033[0;32m'; YELLOW='\033[1;33m'; BLUE='\033[0;34m'; NC='\033[0m'

usage() {
    echo "Usage: $0 -f <logfile> [options]"
    echo ""
    echo "Required:"
    echo "  -f <file>         Log file to analyze"
    echo ""
    echo "Optional filters:"
    echo "  -u <pattern>      URL filter (can be used multiple times)"
    echo "  -t <HH-HH>        Time range filter (e.g., 10-11, 14-15)"
    echo "  -b <minutes>      Bucket size in minutes (default 60)"
    echo "  -n <number>       Top N results (default 10, if multiple -u given = count of -u)"
    echo ""
    echo "Modes:"
    echo "  -R                Real-time monitoring (tail -F)"
    echo "  --historical      Historical analysis (default)"
    echo ""
    echo "Thresholds (alerts if exceeded):"
    echo "  -T200 <n>         Threshold for success responses (200), default=50"
    echo "  -T500 <n>         Threshold for server errors (500), default=10"
    echo "  -TERR <n>         Threshold for all other errors (incl. blank), default=5"
    echo ""
    echo "Examples:"
    echo "  $0 -f caapi.log --historical"
    echo "  $0 -f caapi.log -u uploaddocument -t 10-11"
    echo "  $0 -f caapi.log -b 15 -R"
    echo "  $0 -f caapi.log -T200 100 -T500 20 -TERR 10"
    exit 1
}

# Parse args
while [[ $# -gt 0 ]]; do
    case $1 in
        -f) LOG_FILE="$2"; shift 2 ;;
        -u) URL_PATTERNS+=("$2"); shift 2 ;;
        -t) TIME_RANGES+=("$2"); shift 2 ;;
        -b) BUCKET_MINUTES="$2"; shift 2 ;;
        -n) SHOW_TOP="$2"; shift 2 ;;
        -R) MODE="realtime"; shift ;;
        --historical) MODE="historical"; shift ;;
        -T200) THRESHOLD_200="$2"; shift 2 ;;
        -T500) THRESHOLD_500="$2"; shift 2 ;;
        -TERR) THRESHOLD_ERR="$2"; shift 2 ;;
        -h|--help) usage ;;
        *) echo "Unknown option $1"; usage ;;
    esac
done

[[ -z "$LOG_FILE" ]] && { echo -e "${RED}Error: Log file required${NC}"; usage; }
[[ ! -f "$LOG_FILE" ]] && { echo -e "${RED}Error: Log file '$LOG_FILE' not found${NC}"; exit 1; }

# Auto-adjust top N if multiple -u given
if [[ ${#URL_PATTERNS[@]} -gt 1 ]]; then
    SHOW_TOP=${#URL_PATTERNS[@]}
fi

[[ ${#URL_PATTERNS[@]} -eq 0 ]] && URL_PATTERNS=(".*")
[[ ${#TIME_RANGES[@]} -eq 0 ]] && TIME_RANGES=("0-23")

echo -e "${BLUE}CAAPI Log Analyzer starting...${NC}"
echo " Mode: $MODE | File: $LOG_FILE | Bucket: ${BUCKET_MINUTES}m | Top: $SHOW_TOP"
echo " URL Patterns: ${URL_PATTERNS[*]}"
echo " Time Ranges: ${TIME_RANGES[*]}"
echo " Thresholds: 200=$THRESHOLD_200, 500=$THRESHOLD_500, ERR=$THRESHOLD_ERR"
echo "------------------------------------------------------------"

# Helper: extract hour
extract_hour() {
    echo "$1" | grep -oE 'T([0-9]{2})' | sed 's/T//'
}

# Helper: check hour in ranges
is_hour_in_range() {
    local hour=$1
    for range in "${TIME_RANGES[@]}"; do
        local s=${range%-*} e=${range#*-}
        (( 10#$hour >= 10#$s && 10#$hour <= 10#$e )) && return 0
    done
    return 1
}

# Core processing
process_logs() {
    awk -v bucket="$BUCKET_MINUTES" -v t200="$THRESHOLD_200" -v t500="$THRESHOLD_500" -v terr="$THRESHOLD_ERR" '
    function floor(x) { return int(x) }
    BEGIN { FS="[ ~]"; }
    {
        # Timestamp is always the first token
        ts=$1
        if (ts ~ /^[0-9]{4}-[0-9]{2}-[0-9]{2}T/) {
            split(ts, dt, "T")
            timepart=dt[2]
            split(timepart, hhmmss, ":")
            hour=hhmmss[1]; minute=hhmmss[2]
            bucket_min=floor(minute/bucket)*bucket
            bucket_key=hour ":" sprintf("%02d", bucket_min)
        } else { next }
        
        # Extract ReqURL, SBRespCode, ElapsedTime
        url=""; code=""; etime=""
        for (i=1;i<=NF;i++) {
            if ($i ~ /^ReqURL::/) { sub("ReqURL::","",$i); url=$i }
            if ($i ~ /^SBRespCode::/) { sub("SBRespCode::","",$i); code=$i }
            if ($i ~ /^ElapsedTime::/) { sub("ElapsedTime::","",$i); etime=$i }
        }
        if (url=="") next
        if (code=="") code="BLANK"
        
        key=bucket_key "|" url "|" code
        counts[key]++
        timesum[key]+=etime
    }
    END {
        for (k in counts) {
            split(k, parts, "|")
            bucket=parts[1]; url=parts[2]; code=parts[3]
            c=counts[k]; avg=(timesum[k]>0)?timesum[k]/c:"N/A"
            printf "%s|%s|%s|%d|%s\n", bucket, url, code, c, avg > "/dev/stdout"

            # Spike detection
            if (code=="200" && c>t200) printf "ALERT: Spike on %s %s code=200 count=%d (Thr=%d)\n", url, bucket, c, t200 > "/dev/stderr"
            else if (code=="500" && c>t500) printf "ALERT: Spike on %s %s code=500 count=%d (Thr=%d)\n", url, bucket, c, t500 > "/dev/stderr"
            else if (code!="200" && code!="500" && c>terr) printf "ALERT: Spike on %s %s code=%s count=%d (Thr=%d)\n", url, bucket, code, c, terr > "/dev/stderr"
        }
    }'
}

# Run depending on mode
if [[ "$MODE" == "realtime" ]]; then
    tail -F "$LOG_FILE" | process_logs
else
    cat "$LOG_FILE" | process_logs
fi
ðŸ“˜ Command Summary
1. Historical analysis (default)
./caapi_log_analyzer.sh -f caapi.log


Analyzes full file

Buckets by 60 min

Shows top 10 results

2. Filter by URL & Time
./caapi_log_analyzer.sh -f caapi.log -u uploaddocument -t 10-11


Only uploaddocument URLs

Only logs between 10â€“11h

3. Real-time monitoring
./caapi_log_analyzer.sh -f caapi.log -b 15 -R


Buckets by 15 minutes

Runs live with tail -F

4. Thresholds
./caapi_log_analyzer.sh -f caapi.log -T200 100 -T500 20 -TERR 15


Alerts if:

200 responses >100

500 responses >20

Other/blank responses >15

5. Multiple URLs
./caapi_log_analyzer.sh -f caapi.log -u uploaddocument -u downloaddocument


Auto-adjusts top results to 2
